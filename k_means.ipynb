{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pOi9stg4BqjL"
      ],
      "authorship_tag": "ABX9TyPib81xKf6QzVkb/IC04nvV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagoahl/Digit-recognition/blob/main/k_means.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prev"
      ],
      "metadata": {
        "id": "pOi9stg4BqjL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDT8dOv-sPd0"
      },
      "outputs": [],
      "source": [
        "def create_means(k, dim, mean_bounds):\n",
        "  min = mean_bounds[0]\n",
        "  max = mean_bounds[1]\n",
        "  means = np.random.uniform(min, max, size=(k, dim))\n",
        "  return means"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " np.random.uniform(0, 1, size=(10, 64))"
      ],
      "metadata": {
        "id": "BIyrFg3_00LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assignate(data, means):\n",
        "  assignations = []\n",
        "  for point in data:\n",
        "    distances = [np.linalg.norm(point-means[i]) for i in range(len(means))]\n",
        "    point_cluster = np.argmin(distances)\n",
        "    assignations.append(point_cluster)\n",
        "  return assignations"
      ],
      "metadata": {
        "id": "Aq4Q9-QDEnl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clusterize(data, assignations, k):\n",
        "  clusters = [[] for _ in range(k)]\n",
        "  for j in range(len(assignations)):\n",
        "    assignation = assignations[j]\n",
        "    point = data[j]\n",
        "    clusters[assignation].append(point)\n",
        "  return clusters"
      ],
      "metadata": {
        "id": "8290q7KLJUDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_means(data, clusters, old_means, k, dim, mean_bounds):\n",
        "  means = [np.zeros(2) for _ in range(k)]\n",
        "  i=0\n",
        "  for cluster in clusters:\n",
        "    if len(cluster)==0:\n",
        "      min = mean_bounds[0]\n",
        "      max = mean_bounds[1]\n",
        "      means[i] = np.random.uniform(min, max, size=(k, dim)) #old_means[i]\n",
        "      #print(f'{i} is empty {old_means[i]}')\n",
        "      i+=1\n",
        "      continue\n",
        "    mean = np.mean(cluster, axis=0)\n",
        "    means[i] = mean\n",
        "    i+=1\n",
        "    #print(np.array(cluster).shape)\n",
        "  return np.array(means, dtype=object)"
      ],
      "metadata": {
        "id": "AVwahVz5HGWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delta(i, j):\n",
        "  if i==j:\n",
        "    return 0.0\n",
        "  else:\n",
        "    return 1.0"
      ],
      "metadata": {
        "id": "vwjF_igEeTLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(data, assignations, clusters, means, k):\n",
        "  loss = 0\n",
        "  for i in range(len(means)):\n",
        "    mean = means[i]\n",
        "    for j in range(len(data)):\n",
        "      point = data[j]\n",
        "      #print(f'j:{j}, las:{len(assignations)}, pm:{len(point)},{len(mean)}')\n",
        "      loss += delta(i, assignations[j])*np.linalg.norm(point-mean)\n",
        "  return loss/len(data)"
      ],
      "metadata": {
        "id": "9ON3Ww4Hc6Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_k_means(data, k, dim, mean_bounds,max_iter=100, tolerance=1e-2, live_plot=False, metrics=False):\n",
        "  means = create_means(k=k, dim=dim, mean_bounds=mean_bounds)\n",
        "  for _ in range(max_iter):\n",
        "    assignations = assignate(data, means)\n",
        "    clusters = clusterize(data, assignations, k)\n",
        "    old_means = means\n",
        "    means = update_means(data, clusters, means, k, dim, mean_bounds)\n",
        "    #print(means)\n",
        "    change = np.mean([np.linalg.norm(means[i]-old_means[i]) for i in range(len(means))])\n",
        "    if change < tolerance:\n",
        "      break\n",
        "    if metrics==True:\n",
        "      print(f'Change: {change}')\n",
        "      print(f'Loss: {loss_function(data, assignations, clusters, means, k)}')\n",
        "    if live_plot==True:\n",
        "      summary = pd.DataFrame({\n",
        "        'x': data[:, 0],\n",
        "        'y': data[:, 1],\n",
        "        'cluster': assignations\n",
        "      })\n",
        "      plt.figure(figsize=(6, 6))\n",
        "      sns.scatterplot(data=summary, x='x', y='y',hue='cluster')\n",
        "      plt.scatter(means[:,0], means[:,1], color='r')\n",
        "      plt.show()\n",
        "  return np.array(assignations)"
      ],
      "metadata": {
        "id": "dy0KttDylIIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OOP"
      ],
      "metadata": {
        "id": "CKX4wpyC3yaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('v1.5.8')"
      ],
      "metadata": {
        "id": "vArfdaDKwkr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "JZXiWi-N9KUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KMeans():\n",
        "  def __init__(self, k):\n",
        "    self.k = k\n",
        "\n",
        "  def fit(self, data, mean_bounds=(0, 1.0), max_iter=100000, tolerance=1e-2, live_plot=False, verbose=0):\n",
        "    self.data = data\n",
        "    self.dim = len(self.data[0])\n",
        "    self.normalize()\n",
        "    means = self.create_means(mean_bounds=mean_bounds)\n",
        "    for _ in range(max_iter):\n",
        "      self.assignations = self.assignate(means)\n",
        "      clusters = self.clusterize(self.assignations)\n",
        "      old_means = means\n",
        "      print(means)\n",
        "      means = self.update_means(clusters, mean_bounds)\n",
        "      #print(means)\n",
        "      change = np.mean([np.linalg.norm(means[i]-old_means[i]) for i in range(len(means))])\n",
        "      if change < tolerance:\n",
        "        break\n",
        "      if verbose==1:\n",
        "        print(f'Change: {change} | Loss: {self.loss(self.assignations, clusters, means)} \\n \\n')\n",
        "      if live_plot==True:\n",
        "        summary = pd.DataFrame({\n",
        "          'x': self.data[:, 0],\n",
        "          'y': self.data[:, 1],\n",
        "          'cluster': self.assignations\n",
        "        })\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        sns.scatterplot(data=summary, x='x', y='y',hue='cluster')\n",
        "        plt.scatter(means[:,0], means[:,1], color='r')\n",
        "        plt.show()\n",
        "    return np.array(self.assignations)\n",
        "    \n",
        "  def loss(self, assignations, clusters, means):\n",
        "    loss = 0\n",
        "    for i in range(len(means)):\n",
        "      mean = means[i]\n",
        "      for j in range(len(self.data)):\n",
        "        point = self.data[j]\n",
        "        #print(f'j:{j}, las:{len(assignations)}, pm:{len(point)},{len(mean)}')\n",
        "        loss += self.delta(i, assignations[j])*np.linalg.norm(point-mean)\n",
        "    return loss/len(self.data)\n",
        "\n",
        "  def delta(self, i, j):\n",
        "    if i==j:\n",
        "      return 0.0\n",
        "    else:\n",
        "      return 1.0\n",
        "      \n",
        "  def update_means(self, clusters, mean_bounds):\n",
        "    means = [np.zeros(self.dim) for _ in range(self.k)]\n",
        "    i=0\n",
        "    for cluster in clusters:\n",
        "      if len(cluster)==0:\n",
        "        min = mean_bounds[0]\n",
        "        max = mean_bounds[1]\n",
        "        means[i] = np.random.uniform(min, max, size=(self.k, self.dim)) #old_means[i]\n",
        "        #print(f'{i} is empty {old_means[i]}')\n",
        "        i+=1\n",
        "        continue\n",
        "      mean = np.mean(cluster, axis=0)\n",
        "      means[i] = mean\n",
        "      i+=1\n",
        "      #print(np.array(cluster).shape)\n",
        "    return np.array(means, dtype=object)\n",
        "\n",
        "  def clusterize(self, assignations):\n",
        "    clusters = [[] for _ in range(self.k)]\n",
        "    for j in range(len(assignations)):\n",
        "      assignation = assignations[j]\n",
        "      point = self.data[j]\n",
        "      clusters[assignation].append(point)\n",
        "    return clusters\n",
        "\n",
        "  def assignate(self, means):\n",
        "    assignations = []\n",
        "    for point in self.data:\n",
        "      distances = [np.linalg.norm(point-means[i]) for i in range(len(means))]\n",
        "      point_cluster = np.argmin(distances)\n",
        "      assignations.append(point_cluster)\n",
        "    return assignations\n",
        "\n",
        "  def create_means(self, mean_bounds):\n",
        "    min = mean_bounds[0]\n",
        "    max = mean_bounds[1]\n",
        "    means = np.random.uniform(min, max, size=(self.k, self.dim))\n",
        "    return means\n",
        "          \n",
        "  def normalize(self):\n",
        "    sc = MinMaxScaler()\n",
        "    sc.fit(self.data)\n",
        "    self.data = sc.transform(self.data)\n",
        "\n",
        "  def sort_assignations(self, old, targets):\n",
        "    data = self.assignations\n",
        "    new = data\n",
        "    for x in range(len(data)):\n",
        "      #print('\\n')\n",
        "      observation = data[x]\n",
        "      #print(f'observation:{observation}')\n",
        "      for i in range(len(old)):\n",
        "        #print(i)\n",
        "        #print(old[i], observation)\n",
        "        if old[i] == observation:\n",
        "          #print(f'OK! old:{old[i]}, ob:{observation}')\n",
        "          new[x] = targets[i]\n",
        "    self.assignations = new"
      ],
      "metadata": {
        "id": "RU7gMpqH3zc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  x=x+2"
      ],
      "metadata": {
        "id": "Hn33n5wcRY5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}